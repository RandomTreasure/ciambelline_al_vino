# -*- coding: utf-8 -*-
"""AI_2025_G6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BtpCpJYHaqO_sIPx0JH5yAo88rZJ3rdV

## 0. Import delle librerie e download dei dataset
"""

# Import dei moduli utilizzati in tutte le parti
import numpy as np
import torch
import matplotlib.pyplot as plt

# Scegliamo il dispositivo su cui allenare il modello
device = 'cuda' if torch.cuda.is_available() else 'cpu'

#Definizione di funzioni di utilità
def log(s):
  print('[+]',s)

# Download dei dataset
!wget http://giagu.web.cern.ch/giagu/CERN/P2025/Normal_data.npz > /dev/null
!wget http://giagu.web.cern.ch/giagu/CERN/P2025/G6/Test_data_low.npz > /dev/null
!wget http://giagu.web.cern.ch/giagu/CERN/P2025/G6/Test_data_high.npz > /dev/null

log('Download completato di Normal_data.npz')
log('Download completato di Test_data_low.npz')
log('Download completato di Test_data_high.npz')

"""## 1. Caricamento e Preprocessamento dei Dati"""

from torch.utils.data import DataLoader, TensorDataset, random_split

"""Iniziamo caricando i dataset in array numpy di dimensione (N, 100, 100) per il dataset di train e per i due di test"""

## CARICAMENTO DEI FILE IN ARRAY NUMPY
# Percorsi file
train_path = 'Normal_data.npz'
test_low_path = 'Test_data_low.npz'
test_high_path = 'Test_data_high.npz'

# Caricamento numpy arrays
data_train = np.load(train_path)['normal_data'].astype('float32')
data_test_l = np.load(test_low_path)['test_data'].astype('float32')
data_test_h = np.load(test_high_path)['test_data'].astype('float32')

# Log delle dimensioni
log(f'Normal data shape: {data_train.shape}')
log(f'Test data low shape: {data_test_l.shape}')
log(f'Test data high shape: {data_test_h.shape}')

"""A questo punto poiché i depositi di energia sono limitati nel centro dell'immagine, restringiamo in modo da considerare solo quadrati 40x40 concentrici all'immagine: in questo modo il modello non è influenzato dal fatto che la maggior parte dei pixel sono a valore 0"""

## Ritagliare le immagini in modo che si utilizzi solo un quadrato crop_sizexcrop_size al centro, in modo da utilizzare solo la parte di immagine con informazione

# Dato che tutta l'informazione sta nel centro dell'immagine, ritagliamo in modo da passare al modello solo quello
crop_size = 40  # lato del quadrato
h, w = data_train.shape[1], data_train.shape[2]
cx, cy = h//2, w//2  # centro dell'immagine (50,50)

# Ritaglio sulle numpy arrays (training e test)
data_train = data_train[:, cx-crop_size//2:cx+crop_size//2, cy-crop_size//2:cy+crop_size//2]
data_test_l = data_test_l[:, cx-crop_size//2:cx+crop_size//2, cy-crop_size//2:cy+crop_size//2]
data_test_h = data_test_h[:, cx-crop_size//2:cx+crop_size//2, cy-crop_size//2:cy+crop_size//2]

# Log delle nuove dimensioni degli array
log(f'Normal data shape restricted: {data_train.shape}')
log(f'Test data low shape restricted: {data_test_l.shape}')
log(f'Test data high shape restricted: {data_test_h.shape}')

"""A questo punto rendiamo le immagini binarie, ossia:

*   deposito di energia -> 1.0
*   nessun deposito -> 0.0

Questo perché, avendo le anomalie depositi più concentrati, l'errore di ricostruzione del modello sarà minore rispetto a quello dei dati normali, che hanno una distribuzione degli eventi molto più diffusa e quindi sono più complicati da ricostruire. Possiamo quindi pensare di utilizzare questo errore compiuto nella ricostruzione per discriminare tra eventi normali e anomalie.




"""



"""Infine trasformiamo gli array numpy in tensori Torch e creiamo un dataloader per il training"""

## Trasformazione in tensori torch

# torch.from_numpy converte l'array NumPy in un tensore PyTorch
# unsqueeze(1) aggiunge la dimensione del canale (batch, channel, H, W)

X_train = torch.from_numpy(data_train_norm).unsqueeze(1)  # shape (N,1,100,100)
X_test_l = torch.from_numpy(data_test_l_norm).unsqueeze(1)
X_test_h = torch.from_numpy(data_test_h_norm).unsqueeze(1)

"""Dividiamo il dataset composto di soli eventi normali in

*   Train dataset: 50%
*   Validation dataset: 30%
*   Test dataset: 20%





"""

## Creazione DataLoader per il training
train_dataset = TensorDataset(X_train, X_train)

# Calcola le dimensioni per training, validation e test (50%, 30%, 20%)
train_size = int(0.5 * len(train_dataset))    # 50% per il training
val_size = int(0.3 * len(train_dataset))      # 30% per la validazione
test_size = len(train_dataset) - train_size - val_size  # Resto per il test (20%)

# Suddivisione dei dati in training, validation e test
train_dataset, val_dataset, test_dataset = random_split(train_dataset, [train_size, val_size, test_size])

batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Verifica le dimensioni dei dataset
log(f"Training dataset size: {len(train_loader.dataset)}")
log(f"Validation dataset size: {len(val_loader.dataset)}")
log(f"Test dataset size: {len(test_loader.dataset)}")

"""Creiamo i dataloader per i test high e low"""

test_dataset_l = TensorDataset(X_test_l, X_test_l)
test_dataset_h = TensorDataset(X_test_h, X_test_h)

test_l_loader = DataLoader(test_dataset_l, batch_size=1, shuffle=False)
test_h_loader = DataLoader(test_dataset_h, batch_size=1, shuffle=False)

log(f"Test Low dataset size: {len(test_l_loader.dataset)}")
log(f"Test High dataset size: {len(test_h_loader.dataset)}")

"""A questo punto grafichiamo alcuni esempi per verificare che la parte di dati considerata sia quella con i depositi di energia"""

#Plot di un esempio di dati
fig,axs = plt.subplots(2,3, figsize=(12,8))
idx = np.random.randint(0, len(data_train), 3)
for i, ax in enumerate(axs[0]):
  ax.imshow(data_train[idx[i]])
for i, ax in enumerate(axs[1]):
  ax.imshow(data_train_norm[idx[i]])
fig.suptitle('Esempio di dati di training', fontsize=16)
plt.show()

"""## 2. Costruzione del Modello (Autoencoder)

Abbiamo costruito un autoencoder convoluzionale che utilizza i seguenti layer
*   Encoder:
    *   Conv2d
    *   BarchNorm
    *   Relu
    *   Layer lineare finale

*   Decoder:
    *   ConvTranspose2d
    *   BarchNorm
    *   Relu
    *   Layer lineare iniziale

*   Sigmoid come funzione di output per assicurarsi che l'output sia tra 0 e 1
"""

from torch import nn, optim

## Creazione dell'architettura del modello

class JetAutoencoder(nn.Module):
    def __init__(self, hidden_channels=64, latent_dim=2):
        super().__init__()
        # ─── ENCODER ─────────────────────────────────────────────────────────
        # 40×40 → 20×20 → 10×10 → 5×5
        self.encoder = nn.Sequential(
            # 1 → hidden_channels*3, spatial 40→20
            nn.Conv2d(1, hidden_channels*3, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(hidden_channels*3),
            nn.ReLU(inplace=True),

            # hidden_channels*3 → hidden_channels*2, spatial 20→10
            nn.Conv2d(hidden_channels*3, hidden_channels*2, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(hidden_channels*2),
            nn.ReLU(inplace=True),

            # hidden_channels*2 → hidden_channels, spatial 10→5
            nn.Conv2d(hidden_channels*2, hidden_channels, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(hidden_channels),
            nn.ReLU(inplace=True),

            # Flatten hidden_channels×5×5 → vector
            nn.Flatten(),
            nn.Linear(hidden_channels * 5 * 5, latent_dim)
        )

        # ─── DECODER ─────────────────────────────────────────────────────────
        self.decoder = nn.Sequential(
            # Latent → hidden_channels*5*5
            nn.Linear(latent_dim, hidden_channels * 5 * 5),
            # hidden_channels*5*5 → hidden_channels×5×5
            nn.Unflatten(dim=1, unflattened_size=(hidden_channels, 5, 5)),

            # hidden_channels → hidden_channels*2, spatial 5→10
            nn.ConvTranspose2d(hidden_channels, hidden_channels*2,
                               kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(hidden_channels*2),
            nn.ReLU(inplace=True),

            # hidden_channels*2 → hidden_channels*3, spatial 10→20
            nn.ConvTranspose2d(hidden_channels*2, hidden_channels*3,
                               kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(hidden_channels*3),
            nn.ReLU(inplace=True),

            # hidden_channels*3 → 1, spatial 20→40
            nn.ConvTranspose2d(hidden_channels*3, 1,
                               kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()  # output in [0,1]
        )

    def forward(self, x):
        z = self.encoder(x)   # -> [N, latent_dim]
        x_rec = self.decoder(z)  # -> [N,1,40,40]
        return x_rec, z

"""Abbiamo deciso di costruire questa architettura in modo che riuscisse a ricostruire facilmente immagini con pochi pixel settati ad 1 concentrati in una sola zona, mentre avesse più difficoltà a ricostruire depositi di energia maggiormente delocalizzati.

Il motivo dietro questa scelta sta nel fatto che le anomalie sono per necessità di cose molto più facili da ricostruire avendo solo pochi pixel pari a 1, perciò qualsiasi modello che imparasse a ricostruire bene gli eventi normali avrebbe ricostruito altrettanto bene le anomalie, rendendo impossibile differenziare tra i due tipi di eventi.

La nostra rete ha imparato abbastanza sul problema da non produrre risultati casuali, ma commettendo comunque errori più grandi sugli eventi normali rispetto alle anomalie, permettendoci così di distinguere queste due categorie di eventi.

Una volta definita l'architettura inizializziamo modello, loss e optimizer
"""

## Inizializzazione del modello, loss function e optimizer

# Parametri del modello
latent_dim = 5
hidden_channels = 16

# Inizializzazione del modello
ae = JetAutoencoder(hidden_channels=hidden_channels, latent_dim=latent_dim).to(device)

# Loss function
criterion = nn.BCELoss()

# Optimizer ADAM con scheduler per ridurre learning rate
optimizer = optim.Adam(ae.parameters(), lr=1e-4, weight_decay=1e-5)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

"""Controlliamo che tutto sia come ci aspettiamo e che sia stato inizializzato correttamente"""

## Summary del modello
from torchsummary import summary
# Struttura del modello
print(ae)
# Summary del modello
if torch.cuda.is_available():
  print(summary(ae, input_size=(1, crop_size, crop_size)))

"""## 3. Training del Modello"""

from tqdm.notebook import tqdm

num_epochs = 80
train_losses = []
val_losses = []
best_loss = float('inf')
patience_es = 10
counter_es = 0

pbar = tqdm(total=num_epochs, desc='Training')

for epoch in range(1, num_epochs + 1):
    # Modalità training
    ae.train()
    running_loss = 0.0
    for batch_x, _ in train_loader:
        batch_x = batch_x.to(device)
        optimizer.zero_grad()
        outputs, _ = ae(batch_x)
        loss = criterion(outputs, batch_x)  # Calcola la BCE Loss
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * batch_x.size(0)

    # Calcola la loss di addestramento
    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    # Calcola la loss sul validation set

    # Modalità valutazione (disabilita dropout e batch norm)
    ae.eval()
    val_running_loss = 0.0
    with torch.no_grad():
        for batch_x, _ in val_loader:
            batch_x = batch_x.to(device)
            outputs, _ = ae(batch_x)
            loss = criterion(outputs, batch_x)
            val_running_loss += loss.item() * batch_x.size(0)

    # Calcola la loss di validazione
    val_loss = val_running_loss / len(val_loader.dataset)
    val_losses.append(val_loss)

    # Scheduler per LR
    scheduler.step(val_loss)

    # Early stopping
    if val_loss < best_loss:
        best_loss = val_loss
        counter_es = 0
    else:
        counter_es += 1
    if counter_es >= patience_es:
        log(f"Early stopping at epoch {epoch}, validation loss did not improve for {patience_es} epochs")
        break

    pbar.set_postfix_str(f"Epoch {epoch}/{num_epochs}, Train Loss: {epoch_loss:.8f}, Validation Loss: {val_loss:.8f}, LR: {optimizer.param_groups[0]['lr']:.1e}")
    pbar.update(1)

log(f'Training di {num_epochs} epoche completato')

"""Grafichiamo train e validation loss in funzione delle epoche"""

# Plot della curva di loss di training e validazione
import matplotlib.pyplot as plt
plt.figure(figsize=(6,4))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.grid(alpha=0.4)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Learning Curve Autoencoder')
plt.legend()
plt.show()

"""Controlliamo la ricostruzione delle immagini per assicurarci che non produca rumore casuale e non si verifichino checkboard o grid artifacts"""

#Check che la ricostruzione sia buona
for x, _ in val_loader:

  ae.eval()
  x = x.to(device)
  x_rec, _ = ae(x)
  break

plt.imshow(x[0][0].cpu())
plt.show()
plt.imshow(x_rec[0][0].cpu().detach().numpy())
plt.show()

"""## 4. Valutazione delle Anomalie sui Test Samples

Per prima cosa calcoliamo gli errori di ricostruzione per i test dataset
"""

# Funzione per calcolare errore di ricostruzione medio
@torch.no_grad()
def compute_recon_error(loader):
    ae.eval()
    errors = []
    for xb, _ in loader:
        xb = xb.to(device)
        xb_rec, _ = ae(xb)

        loss = criterion(xb_rec, xb)

        errors.append(loss.item())

    return np.array(errors)

# Calcolo degli errori
errors_train = compute_recon_error(test_loader)
errors_l = compute_recon_error(test_l_loader)
errors_h = compute_recon_error(test_h_loader)

"""Dato che in media la ricostruzione delle anomalie avrà un errore minore in quanto i depositi di energia sono più concentrati, scegliamo un upperbound per l'errore in modo che l'8% degli errori di ricostruzione di eventi normali sia inferiore a questa threshold"""

# Soglia per FPR ~8%
FPR_target = 0.08
threshold = np.percentile(errors_train, 100 * (FPR_target))
print(f"Soglia FPR = {FPR_target*100}%: {threshold:.6f}")

# Stima frazione anomalia
frac_l = np.mean(errors_l < threshold)
frac_h = np.mean(errors_h < threshold)
print(f"Frazione stimata anomalie (low): {frac_l*100:.2f}%")
print(f"Frazione stimata anomalie (high): {frac_h*100:.2f}%")

"""Come si può vedere abbiamo $f_l < f_h$, con $f_l < 45\%$ e $f_h>55\%$ in perfetto accordo con quanto atteso.

Plottiamo gli istogrammi degli errori di ricostruzione e la threshold
"""

min_err = min([errors_train.min(), errors_l.min(), errors_h.min()])
max_err = max([errors_l.max(), errors_h.max(), errors_l.max()])

plt.hist(errors_train, label='normal', alpha=0.4, bins=np.linspace(min_err, max_err, 100), density=True)
plt.hist(errors_l, label='low', alpha=0.4, bins=np.linspace(min_err, max_err, 100), density=True)
plt.hist(errors_h, label='high', alpha=0.4, bins=np.linspace(min_err, max_err, 100), density=True)
plt.vlines(threshold, 0, 20, label='threshold', linestyle='--')
plt.grid(alpha=0.3)
plt.legend()
plt.xlim(min_err, max_err)
plt.show()

"""Possiamo vedere che le distribuzioni delle reconstruction loss sono effettivamente diverse per i tre dataset. Come ci aspettavamo, maggiore è la concentrazione di anomalie nel dataset, più in basso si sposta il picco della distribuzione.

## 5. Visualizzazione dello Spazio Latente e Clustering

Iniziamo calcolando la rappresentazione latente per i due test dataset
"""

# Estrazione dei vettori latenti per i test set
@torch.no_grad()
def get_latent(data_tensor):
    ae.eval()
    zs = []
    loader = DataLoader(data_tensor, batch_size=256)
    for xb in loader:
        xb = xb.to(device)
        _, z = ae(xb)
        zs.append(z.cpu().numpy())
    return np.vstack(zs)

Z_l = get_latent(X_test_l)  # latenti low
Z_h = get_latent(X_test_h)  # latenti high
Z_all = np.vstack([Z_l, Z_h])  # combinazione per analisi congiunta

"""Su questo spazio latente facciamo riduzione dimensionale"""

# Riduzione dimensionale via PCA e t-SNE
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

pca = PCA(n_components=2)
Z_pca = pca.fit_transform(Z_all)  # proiezione su 2 componenti principali

tsne = TSNE(n_components=2, random_state=42)
Z_tsne = tsne.fit_transform(Z_all)  # t-SNE per embedding non-lineare

"""Plottiamo la riduzione dimensionale e differenziamo gli eventi anomalie da quelli normali"""

anomaly_labels = np.concatenate([errors_l, errors_h]) < threshold

# Funzione per scatter plot colored by anomaly label
def plot_anomaly(z, title):
    plt.figure(figsize=(6,5))
    scatter = plt.scatter(z[:,0], z[:,1], c=anomaly_labels.astype(int), cmap='bwr', alpha=0.6, s=2)
    # crea legenda manuale
    from matplotlib.patches import Patch
    legend_elements = [Patch(facecolor='blue', label='Normale'), Patch(facecolor='red', label='Anomalia')]
    plt.legend(handles=legend_elements)
    plt.title(title)
    plt.xlabel('Dim 1')
    plt.ylabel('Dim 2')
    plt.show()

# Plot delle rappresentazioni dividendo tra anomalie e eventi normali
plot_anomaly(Z_pca, 'Latent Space PCA')
plot_anomaly(Z_tsne, 'Latent Space t-SNE')

"""Per avere anche una rappresentazione più chiara rifacciamo gli stessi plot differenziando tra anomalie e normali e per il dataset da cui vengono"""

# Creiamo 4 categorie:
# 0 = Normali in test_low, 1 = Anomalie in test_low,
# 2 = Normali in test_high, 3 = Anomalie in test_high

# Ricostruzione error per separare normali e anomalie
norm_l = errors_l >= threshold
anom_l = errors_l < threshold
norm_h = errors_h >= threshold
anom_h = errors_h < threshold

# Costruiamo array di label con lunghezza len(Z_all)
labels4 = np.zeros(len(Z_all), dtype=int)

# Prima metà corrisponde a test_low
labels4[:len(Z_l)][anom_l] = 1  # anomalie low
# test_low normali restano 0

# Seconda metà corrisponde a test_high
start_h = len(Z_l)
labels4[start_h:][norm_h] = 2  # normali high -> label 2
labels4[start_h:][anom_h] = 3  # anomalie high -> label 3

# Definiamo una mappa di colori
cmap4 = {0: 'royalblue', 1: 'darkorange', 2: 'maroon', 3: 'seagreen'}
colors = [cmap4[l] for l in labels4]

# Funzione per scatter plot con 4 colori e legenda
from matplotlib.patches import Patch
import matplotlib.lines as mlines

def plot_four_labels(z, title):
    plt.figure(figsize=(6,5))
    for lbl, col in cmap4.items():
        idx = labels4 == lbl
        plt.scatter(z[idx,0], z[idx,1], c=col, label=
                    ['Norm_low','Anom_low','Norm_high','Anom_high'][lbl], alpha=0.6, s=2)

    # Creazione manuale degli elementi della legenda con marker size specificato
    legend_elements = [mlines.Line2D([], [], color=cmap4[0], marker='o', linestyle='None',
                                     markersize=5, label='Norm_low'),
                       mlines.Line2D([], [], color=cmap4[1], marker='o', linestyle='None',
                                     markersize=5, label='Anom_low'),
                       mlines.Line2D([], [], color=cmap4[2], marker='o', linestyle='None',
                                     markersize=5, label='Norm_high'),
                       mlines.Line2D([], [], color=cmap4[3], marker='o', linestyle='None',
                                     markersize=5, label='Anom_high')]


    plt.legend(handles=legend_elements)
    plt.title(title)
    plt.grid(alpha=0.3)
    plt.xlabel('Dim 1')
    plt.ylabel('Dim 2')
    plt.show()

# Plot con PCA e t-SNE
plot_four_labels(Z_pca, 'Latent Space PCA con 4 Label')
plot_four_labels(Z_tsne, 'Latent Space t-SNE con 4 Label')

def plot_highlighted_category(z, title_prefix, labels, cmap, highlighted_label, ax):
    # Plot dei punti non evidenziati
    for lbl, col in cmap.items():
        idx = labels == lbl
        alpha = 0.1 if lbl != highlighted_label else 1.0 # differenziamo l'alpha
        if lbl != highlighted_label:
            ax.scatter(z[idx, 0], z[idx, 1], c=col, label=['Norm_low', 'Anom_low', 'Norm_high', 'Anom_high'][lbl], alpha=alpha, s=2)

    # Plot dei punti evidenziati
    for lbl, col in cmap.items():
        idx = labels == lbl
        alpha = 1.0 if lbl == highlighted_label else 0.1
        if lbl == highlighted_label:
             ax.scatter(z[idx, 0], z[idx, 1], c=col, label=['Norm_low', 'Anom_low', 'Norm_high', 'Anom_high'][lbl], alpha=1.0, s=2)


    category_name = ['Norm_low', 'Anom_low', 'Norm_high', 'Anom_high'][highlighted_label]
    ax.set_title(f'{title_prefix} - {category_name}')
    ax.set_xlabel('Dim 1')
    ax.set_ylabel('Dim 2')
    ax.grid(alpha=0.3)

    legend_elements = [mlines.Line2D([], [], color=cmap[0], marker='o', linestyle='None',
                                     markersize=5, label='Norm_low'),
                       mlines.Line2D([], [], color=cmap[1], marker='o', linestyle='None',
                                     markersize=5, label='Anom_low'),
                       mlines.Line2D([], [], color=cmap[2], marker='o', linestyle='None',
                                     markersize=5, label='Norm_high'),
                       mlines.Line2D([], [], color=cmap[3], marker='o', linestyle='None',
                                     markersize=5, label='Anom_high')]

    ax.legend(handles=legend_elements, loc='best')


# Plot per PCA
fig_pca, axes_pca = plt.subplots(1, 4, figsize=(20, 5))
for i in range(4):
    plot_highlighted_category(Z_pca, 'PCA', labels4, cmap4, i, axes_pca[i])
fig_pca.suptitle('Latent Space PCA - Highlighted Categories', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()


# Plot per t-SNE
fig_tsne, axes_tsne = plt.subplots(1, 4, figsize=(20, 5))
for i in range(4):
    plot_highlighted_category(Z_tsne, 't-SNE', labels4, cmap4, i, axes_tsne[i])
fig_tsne.suptitle('Latent Space t-SNE - Highlighted Categories', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""Già dalla rappresentazione ridotta possiamo vedere che lo spazio latente è separato tra anomalie e eventi normali, ulteriore conferma che il modello abbia effettivamente imparato a distinguere tra i due tipi di eventi.

Proviamo a vedere se lo spazio latente è separato facendo clustering con GMM
"""

# Clustering con Gaussian Mixture Model (GMM)
from sklearn.mixture import GaussianMixture

gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=1337)
gmm_labels = gmm.fit_predict(Z_all)

# Calcolo purezza: per ogni cluster, percentuale di elementi del cluster che condividono la label di maggioranza
purity_scores = []
for cluster_id in np.unique(gmm_labels):
    idx = (gmm_labels == cluster_id)
    # conta 0 e 1 delle anomaly_labels nel cluster
    counts = np.bincount(anomaly_labels[idx].astype(int))
    majority = counts.max()
    purity = majority / counts.sum()
    purity_scores.append(purity)
    log(f"Cluster {cluster_id}: purezza = {purity*100:.2f}% (size {counts.sum()}) -> {'anomaly' if counts[1] == majority else 'normal'}")

# Purezza overall (media pesata)
overall_purity = np.sum(purity_scores * np.bincount(gmm_labels) / len(Z_all))
log(f"Purezza globale del clustering: {overall_purity*100:.2f}%")

"""Come è possibile vedere lo spazio latente è ben clusterato e diviso tra eventi normali ed eventi anomali. Questo, insieme alle frazioni stimate di anomalie nei due dataset compatibili con le aspettative che avevamo ci permette di concludere che il modello funziona e riesce a distinguere bene i due tipi di eventi."""